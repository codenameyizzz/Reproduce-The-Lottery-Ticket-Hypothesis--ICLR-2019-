{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7538c211",
   "metadata": {},
   "source": [
    "# Reproducing The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks (ICLR 2019)\n",
    "\n",
    "### This script reproduces the core experiments of the Lottery Ticket Hypothesis:\n",
    "- Training LeNet on MNIST\n",
    "- Iterative magnitude-based pruning\n",
    "- Resetting surviving weights to initial values\n",
    "- Early stopping on validation set\n",
    "- Final plots include accuracy vs iteration and accuracy vs sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6f0fd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used library\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Model and Utility\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def setup_data(batch_size=128):\n",
    "    transform = transforms.ToTensor()\n",
    "    full_train = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "    test_set = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "    train_len = int(0.9 * len(full_train))\n",
    "    val_len = len(full_train) - train_len\n",
    "    train_data, val_data = random_split(full_train, [train_len, val_len])\n",
    "    return (\n",
    "        DataLoader(train_data, batch_size=batch_size, shuffle=True, pin_memory=True),\n",
    "        DataLoader(val_data, batch_size=1000, pin_memory=True),\n",
    "        DataLoader(test_set, batch_size=1000, pin_memory=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "188320b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AMP training step\n",
    "def train_amp(model, loader, optimizer, criterion, scaler, device):\n",
    "    model.train()\n",
    "    for data, target in loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "# Evaluation step (shared by val/test)\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    correct, total_loss = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            total_loss += criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "    accuracy = 100. * correct / len(loader.dataset)\n",
    "    return total_loss / len(loader), accuracy\n",
    "\n",
    "# Pruning function (iterative pruning support)\n",
    "def prune_by_percentile(model, percent, current_mask=None):\n",
    "    all_weights = []\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            masked = param if current_mask is None else param * current_mask.get(name, 1)\n",
    "            all_weights += list(masked.abs().flatten().cpu().detach().numpy())\n",
    "    threshold = np.percentile(all_weights, percent)\n",
    "    new_mask = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            masked = param if current_mask is None else param * current_mask.get(name, 1)\n",
    "            new_mask[name] = (masked.abs() > threshold).float()\n",
    "    return new_mask\n",
    "\n",
    "# Reset with mask\n",
    "def apply_mask_and_reset(model, initial_weights, mask_dict):\n",
    "    with torch.no_grad():\n",
    "        for name, param in model.named_parameters():\n",
    "            if name in mask_dict:\n",
    "                param.copy_(initial_weights[name] * mask_dict[name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abca0e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment based on paper (5x trials, 5x Iteration per trials)\n",
    "def run_full_experiment(device, prune_percent=20, max_iterations=5, early_stop_patience=3, num_trials=5):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    all_trials_results = []\n",
    "\n",
    "    train_loader, val_loader, test_loader = setup_data()\n",
    "\n",
    "    for trial in range(num_trials):\n",
    "        print(f\"\\n[Trial {trial + 1}/{num_trials}] Starting new trial...\")\n",
    "        model = LeNet().to(device)\n",
    "        scaler = GradScaler()\n",
    "        initial_weights = {k: v.clone() for k, v in model.state_dict().items()}\n",
    "        current_mask = {k: torch.ones_like(v) for k, v in initial_weights.items() if 'weight' in k}\n",
    "        trial_accs = []\n",
    "\n",
    "        for iteration in range(max_iterations):\n",
    "            print(f\"\\n Iteration {iteration + 1}/{max_iterations} (Pruning {prune_percent}% of remaining weights)\")\n",
    "            model.load_state_dict(initial_weights)\n",
    "            apply_mask_and_reset(model, initial_weights, current_mask)\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "            best_val_acc = 0\n",
    "            patience = 0\n",
    "            last_test_acc = 0\n",
    "\n",
    "            for epoch in range(1, 51):\n",
    "                train_amp(model, train_loader, optimizer, criterion, scaler, device)\n",
    "                _, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "                _, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "                print(f\"     [Epoch {epoch:2d}] Val Acc = {val_acc:.2f}% | Test Acc = {test_acc:.2f}%\")\n",
    "\n",
    "                if val_acc > best_val_acc:\n",
    "                    best_val_acc = val_acc\n",
    "                    patience = 0\n",
    "                else:\n",
    "                    patience += 1\n",
    "\n",
    "                if patience >= early_stop_patience:\n",
    "                    print(f\"Early stopping triggered after {epoch} epochs (patience={early_stop_patience})\")\n",
    "                    break\n",
    "\n",
    "                last_test_acc = test_acc\n",
    "\n",
    "            print(f\"Iteration {iteration + 1} finished with Test Accuracy = {last_test_acc:.2f}%\\n\")\n",
    "            trial_accs.append(last_test_acc)\n",
    "            current_mask = prune_by_percentile(model, prune_percent, current_mask)\n",
    "\n",
    "        print(f\"[Trial {trial + 1}] Completed with final accuracies: {trial_accs}\\n\")\n",
    "        all_trials_results.append(trial_accs)\n",
    "\n",
    "    return np.array(all_trials_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5de69402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy vs Prunning \n",
    "def plot_accuracy_vs_iteration(all_trials_results):\n",
    "    mean_accs = np.mean(all_trials_results, axis=0)\n",
    "    std_accs = np.std(all_trials_results, axis=0)\n",
    "    iterations = list(range(1, len(mean_accs) + 1))\n",
    "\n",
    "    plt.figure(figsize=(7, 4.5))\n",
    "    plt.errorbar(iterations, mean_accs, yerr=std_accs, fmt='o-', capsize=5, elinewidth=1.8, color='navy', label='Accuracy ± Std')\n",
    "    plt.xticks(iterations, [f'Iter {i}' for i in iterations])\n",
    "    plt.xlabel('Pruning Iteration', fontsize=12)\n",
    "    plt.ylabel('Test Accuracy (%)', fontsize=12)\n",
    "    plt.title('Test Accuracy Across Iterative Pruning', fontsize=13)\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8a485b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy vs Sparsity\n",
    "def plot_accuracy_vs_sparsity(all_trials_results, prune_percent):\n",
    "    remaining_weights = [100]\n",
    "    acc_means = [np.mean(all_trials_results[:, 0])]\n",
    "    acc_stds = [np.std(all_trials_results[:, 0])]\n",
    "\n",
    "    current_remain = 100\n",
    "    for i in range(1, all_trials_results.shape[1]):\n",
    "        current_remain *= (1 - prune_percent / 100)\n",
    "        remaining_weights.append(round(current_remain, 1))\n",
    "        acc_means.append(np.mean(all_trials_results[:, i]))\n",
    "        acc_stds.append(np.std(all_trials_results[:, i]))\n",
    "\n",
    "    plt.figure(figsize=(7, 4.5))\n",
    "    plt.errorbar(remaining_weights, acc_means, yerr=acc_stds, fmt='o-', capsize=5, elinewidth=1.8, color='green', label='Accuracy ± Std')\n",
    "    plt.xlabel('Weights Remaining (%)', fontsize=12)\n",
    "    plt.ylabel('Test Accuracy (%)', fontsize=12)\n",
    "    plt.title('Test Accuracy vs Sparsity', fontsize=13)\n",
    "    plt.xticks(remaining_weights)\n",
    "    plt.gca().invert_xaxis()\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a310cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 1/5] Starting new trial...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeezx\\AppData\\Local\\Temp\\ipykernel_28720\\1045693281.py:11: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Iteration 1/5 (Pruning 20% of remaining weights)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeezx\\AppData\\Local\\Temp\\ipykernel_28720\\3139731351.py:7: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     [Epoch  1] Val Acc = 96.00% | Test Acc = 96.86%\n",
      "     [Epoch  2] Val Acc = 97.60% | Test Acc = 98.06%\n",
      "     [Epoch  3] Val Acc = 97.77% | Test Acc = 98.14%\n"
     ]
    }
   ],
   "source": [
    "# Run Full Experiment\n",
    "results = run_full_experiment(device, prune_percent=20, max_iterations=5, early_stop_patience=3, num_trials=5)\n",
    "\n",
    "# Visualiation\n",
    "plot_accuracy_vs_iteration(results)\n",
    "plot_accuracy_vs_sparsity(results, prune_percent=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3adc43-4232-4f5a-a60d-3bae8ad2a7dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
